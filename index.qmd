```{r}
#| label: setup
#| include: false

source(here::here("R", "_setup.R"))
```

<!-- badges: start -->
[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://img.shields.io/badge/Repo%20Status-Active-12DA12.svg)](https://www.repostatus.org/#inactive)
[![OSF DOI](https://img.shields.io/badge/OSF-10.17605/OSF.IO/8J94M-1284C5.svg)](https://doi.org/10.17605/OSF.IO/8J94M)
[![License: MIT](https://img.shields.io/badge/License-MIT-10D810.svg)](https://choosealicense.com/licenses/mit/)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
<!-- badges: end -->

## Overview

This report contains a reproducible pipeline for processing [SISVAN](https://sisaps.saude.gov.br/sisvan/) microdata on nutritional status monitoring in Brazil (2008–2023). The main goal is to provide a open and reliable workflow for processing these data, supporting research and informed public policy decisions.

::: {.callout-warning}
This pipeline is still under development and may not be fully functional.

This warning will be removed once the pipeline is complete.
:::

## Problem

The Food and Nutrition Surveillance System ([SISVAN](https://sisaps.saude.gov.br/sisvan/)) is a strategic tool for monitoring the nutritional status of the Brazilian population, particularly those served by Brazil's Unified Health System ([SUS](https://www.gov.br/saude/pt-br/sus)). However, despite its broad scope and importance, the anthropometric data recorded in SISVAN often suffer from quality issues that limit their usefulness for rigorous analyses and evidence-based policymaking [@silva2023a].

Multiple factors contribute to these quality concerns, including the lack of standardized measurement protocols, variability in staff training, inconsistencies in data entry and processing, and incomplete population coverage [@bagni2015; @corsi2017; @perumal2020]. To assess and improve data quality, several indicators have been proposed and applied, such as population coverage [@nascimento2017; @mourao2020], completeness of birth dates and anthropometric measurements [@finaret2018; @nannan2019], digit preference for age, height, and weight [@lyons-amos2017; @bopp2008], the percentage of biologically implausible values [@lawman2015], and the dispersion and distribution of standardized weight and height measurements [@perumal2020; @mei2007].

In light of this, there is a need for an open and reproducible pipeline for processing SISVAN microdata, aiming to identify, correct, or remove problematic records and ensure greater consistency, completeness, and plausibility of the information for use in research and public policy.

## Data Availability

::: {style="text-align: left;"}
[![](https://img.shields.io/badge/OSF-10.17605/OSF.IO/8J94M-1284C5.svg)](https://doi.org/10.17605/OSF.IO/8J94M)
:::

The processed data are available in both `csv` and `rds` formats via a dedicated repository on the Open Science Framework ([OSF](https://osf.io/)), accessible [here](https://doi.org/10.17605/OSF.IO/8J94M). A metadata file is included alongside the validated data. You can also access these files directly from R using the [`osfr`](https://docs.ropensci.org/osfr/) package.

A backup copy of the raw data is also available in OSF. You can access it [here](https://doi.org/10.17605/OSF.IO/SY8EC).

## Methods

### Source of Data

The data used in this analysis come from the following sources:

- Brazil’s Food and Nutrition Surveillance System ([SISVAN](https://sisaps.saude.gov.br/sisvan/)), which provides microdata on nutritional status monitoring in Brazil [@sisvana].
- The Brazilian Institute of Geography and Statistics ([IBGE](https://www.ibge.gov.br/)), which provides official territorial data for Brazilian municipalities. These data were accessed using the [`orbis`](https://danielvartan.github.io/orbis/) and [`geobr`](https://ipeagit.github.io/geobr) R packages [@vartanianq; @pereira].
- The Department of Informatics of the Brazilian Unified Health System ([DATASUS](https://datasus.saude.gov.br/)) platform, which provides annual population estimates for Brazil by municipality, age, and sex for the period 2000-2024 [@datasusb]. For practicality and better organization, the DATASUS data used in this pipeline is provided through a separate reproducible pipeline, available [here](https://sustentarea.github.io/datasus-pop-estimates/) [@vartanian2025b].

For technical information about the raw dataset, see the official [technical note](http://tabnet.datasus.gov.br/cgi/SISVAN/CNV/notas_sisvan.html) (in Portuguese).

### Data Munging

The data munging followed the data science workflow outlined by @wickham2023e, as illustrated in [@fig-wickham-at-al-2024-figure-1]. All processes were made using the [Quarto](https://quarto.org/) publishing system [@allaire], the [R programming language](https://www.r-project.org/) [@rcoreteama] and several R packages.

The [tidyverse](https://www.tidyverse.org/) and [rOpenSci](https://ropensci.org/) peer-reviewed package ecosystem and other R packages adherents of the tidy tools manifesto [@wickham2023c] were prioritized. All processes were made in order to provide result transparency and reproducibility.

::: {#fig-wickham-at-al-2024-figure-1}
![](images/wickham-at-al-2024-figure-1.png){width=75%}

[Source: Reproduced from @wickham2023e.]{.legend}

Data science workflow created by Wickham, Çetinkaya-Runde, and Grolemund.
:::

### Data Validation

Different validation techniques were used to ensure data quality and reliability:

- The amount of data imported from the raw files were compared to the amount of data returned by [SISVAN Online Data Access Tool](https://sisaps.saude.gov.br/sisvan/relatoriopublico/).
- Duplicates were removed based on distinct combinations of the variables `id`, `age`, `date` (date of the individual's nutritional assessment), `weight`, and `height`.
- The number of nutritional assessments were compared to the estimated number of children in the population.

@silva2023a quality indicators were also used for validation. Refer to the article for more details.

### Code Style

The Tidyverse [code style guide](https://style.tidyverse.org/) and [design principles](https://design.tidyverse.org/) were followed to ensure consistency and enhance readability.

### Reproducibility

The pipeline is fully reproducible and can be run again at any time. See the [README](https://github.com/danielvartan/datasus-pop-estimates/blob/main/README.md) file in the code repository to learn how to run it.

## Setting the Environment

```{r}
#| eval: false
#| code-fold: false

library(brandr)
library(cli)
library(dplyr)
library(fs)
library(ggplot2)
library(groomr) # github.com/danielvartan/groomr
library(here)
library(httr2)
library(lubridate)
library(orbis) # github.com/danielvartan/orbis
library(osfr)
library(pal) # gitlab.com/rpkg.dev/pal
library(plotr) # github.com/danielvartan/plotr
library(readr)
library(tidyr)
library(utils)
library(vroom)
```

```{r}
#| eval: false
#| include: false
#| code-fold: false

source(here::here("R", "waz.R"))
```

```{r}
#| include: false

library(dplyr)
library(ggplot2)
library(vroom)
```

## Setting the Initial Variables

```{r}
#| code-fold: false

year <- 2017
```

```{r}
#| code-fold: false

age_limits <- c(0, 4)
```

::: {.callout-note}
Click [here](https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SISVAN/estado_nutricional/Dicion%C3%A1rio+de+Dados+-+Estado+Nutricional.pdf) to access the microdata data dictionary (in Portuguese).
:::

```{r}
#| code-fold: false

col_selection <- c(
  "CO_PESSOA_SISVAN",
  "CO_MUNICIPIO_IBGE",
  "DT_ACOMPANHAMENTO",
  "SG_SEXO",
  "NU_IDADE_ANO",
  "NU_PESO",
  "NU_ALTURA"
)
```

## Downloading the Data

::: {.callout-note}
SISVAN microdata files are very large. For practical reasons, some code chunks have `eval: false` set to prevent downloading the data each time the report is rendered. When running the pipeline in a loop or for full automation, remove these lines to enable automatic downloading.
:::

```{r}
if (!dir.exists(here::here("data"))) dir.create("data")
```

```{r}
#| code-fold: false

raw_file_pattern <- paste0("raw-", year)
```

```{r}
#| eval: false
#| code-fold: false

file <- here::here("data", paste0(raw_file_pattern, ".zip"))

paste0(
    "https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SISVAN/",
    "estado_nutricional/sisvan_estado_nutricional_",
    year,
    ".zip"
  ) |>
  httr2::request() |>
  httr2::req_progress() |>
  httr2::req_perform(file)
```

## Unzipping the Data

```{r}
#| eval: false

file <-
  file |>
  utils::unzip(exdir = here::here("data"), overwrite = TRUE)
```

```{r}
#| eval: false

file <-
  file |>
  fs::file_move(here::here("data", paste0(raw_file_pattern, ".csv")))
```

```{r}
#| eval: false

fs::file_delete(here::here("data", paste0(raw_file_pattern, ".zip")))
```

## Checking Data Dimensions

```{r}
#| echo: false

raw_file_pattern <- paste0("raw-", year)

file <- here::here("data", paste0(raw_file_pattern, ".csv"))
```

```{r}
#| code-fold: false

file |> groomr::peek_csv_file(delim = ";", skip = 0, has_header = TRUE)
```

## Reading and Filtering the Data

::: {.callout-note}
We use the [`vroom`](https://vroom.r-lib.org/) R package together with the [AWK](https://en.wikipedia.org/wiki/AWK) programming language to efficiently handle large datasets and mitigate memory issues. This approach allows the pipeline to run locally on most machines, though we recommend a minimum of 12 GB of RAM for optimal performance. Alternatively, the pipeline can also be executed on cloud platforms such as [Google Colab](https://colab.research.google.com/) or [RStudio Cloud](https://rstudio.cloud/).
:::

```{r}
#| code-fold: false

col_names <- c(
  "CO_ACOMPANHAMENTO",
  "CO_PESSOA_SISVAN",
  "ST_PARTICIPA_ANDI",
  "CO_MUNICIPIO_IBGE",
  "SG_UF",
  "NO_MUNICIPIO",
  "CO_CNES",
  "NU_IDADE_ANO",
  "NU_FASE_VIDA",
  "DS_FASE_VIDA",
  "SG_SEXO",
  "CO_RACA_COR",
  "DS_RACA_COR",
  "CO_POVO_COMUNIDADE",
  "DS_POVO_COMUNIDADE",
  "CO_ESCOLARIDADE",
  "DS_ESCOLARIDADE",
  "DT_ACOMPANHAMENTO",
  "NU_COMPETENCIA",
  "NU_PESO",
  "NU_ALTURA",
  "DS_IMC",
  "DS_IMC_PRE_GESTACIONAL",
  "PESO X IDADE",
  "PESO X ALTURA",
  "CRI. ALTURA X IDADE",
  "CRI. IMC X IDADE",
  "ADO. ALTURA X IDADE",
  "ADO. IMC X IDADE",
  "CO_ESTADO_NUTRI_ADULTO",
  "CO_ESTADO_NUTRI_IDOSO",
  "CO_ESTADO_NUTRI_IMC_SEMGEST",
  "CO_SISTEMA_ORIGEM_ACOMP",
  "SISTEMA_ORIGEM_ACOMP"
)
```

```{r}
#| code-fold: false

schema <- vroom::cols(
  CO_ACOMPANHAMENTO = vroom::col_character(),
  CO_PESSOA_SISVAN = vroom::col_character(),
  ST_PARTICIPA_ANDI = vroom::col_character(),
  CO_MUNICIPIO_IBGE = vroom::col_integer(),
  SG_UF = vroom::col_factor(),
  NO_MUNICIPIO = vroom::col_character(), # ? vroom::col_factor()
  CO_CNES = vroom::col_integer(),
  NU_IDADE_ANO = vroom::col_integer(),
  NU_FASE_VIDA = vroom::col_character(), # decimal mark = "." (double)
  DS_FASE_VIDA = vroom::col_factor(),
  SG_SEXO = vroom::col_factor(),
  CO_RACA_COR = vroom::col_character(),
  DS_RACA_COR = vroom::col_factor(),
  CO_POVO_COMUNIDADE = vroom::col_integer(),
  DS_POVO_COMUNIDADE = vroom::col_factor(),
  CO_ESCOLARIDADE = vroom::col_character(),
  DS_ESCOLARIDADE = vroom::col_factor(),
  DT_ACOMPANHAMENTO = vroom::col_date(),
  NU_COMPETENCIA = vroom::col_integer(),
  NU_PESO = vroom::col_double(),
  NU_ALTURA = vroom::col_integer(),
  DS_IMC = vroom::col_double(),
  DS_IMC_PRE_GESTACIONAL = vroom::col_character(), # decimal mark = "." (double)
  "PESO X IDADE" = vroom::col_factor(),
  "PESO X ALTURA" = vroom::col_factor(),
  "CRI. ALTURA X IDADE" = vroom::col_factor(),
  "CRI. IMC X IDADE" = vroom::col_factor(),
  "ADO. ALTURA X IDADE" = vroom::col_factor(),
  "ADO. IMC X IDADE" = vroom::col_factor(),
  CO_ESTADO_NUTRI_ADULTO = vroom::col_factor(),
  CO_ESTADO_NUTRI_IDOSO = vroom::col_factor(),
  CO_ESTADO_NUTRI_IMC_SEMGEST = vroom::col_factor(),
  CO_SISTEMA_ORIGEM_ACOMP = vroom::col_integer(),
  SISTEMA_ORIGEM_ACOMP = vroom::col_factor()
)
```

::: {.callout-important}
You may see warning messages about failed parsing. These warnings are expected due to minor inconsistencies in the SISVAN raw data and do not affect the overall analysis.
:::

```{r}
#| warning: false
#| code-fold: false

data <-
  vroom::vroom(
     # Uses `pipe()` and `awk` to filter data to avoid loading the
     # entire file into memory.
    file = pipe(
      paste(
        "awk -F ';' '{ if (",
        "($8 >= ", age_limits[1], ") && ($8 <= ", age_limits[2], ")",
        ") { print } }'",
        file
      )
    ),
    delim = ";",
    col_names = col_names,
    col_types = schema,
    col_select = dplyr::all_of(col_selection),
    id = NULL,
    skip = 0,
    n_max = Inf,
    na = c("", "NA"),
    quote = "\"",
    comment = "",
    skip_empty_rows = TRUE,
    trim_ws = TRUE,
    escape_double = TRUE,
    escape_backslash = FALSE,
    locale = vroom::locale(
      date_names = "pt",
      date_format = "%d/%m/%Y",
      time_format = "%H:%M:%S",
      decimal_mark = ",",
      grouping_mark = ".",
      tz = "America/Sao_Paulo",
      encoding = readr::guess_encoding(file)$encoding[1]
    ),
    guess_max = 100,
    altrep = TRUE,
    num_threads = vroom:::vroom_threads(),
    progress = vroom::vroom_progress(),
    show_col_types = NULL,
    .name_repair = "unique"
  )
```

```{r}
#| warning: false
#| code-fold: false

data |> dplyr::glimpse()
```

## Renaming the Data

```{r}
#| code-fold: false

data <-
  data |>
  janitor::clean_names() |>
  dplyr::rename(
    id = co_pessoa_sisvan,
    municipality_code = co_municipio_ibge,
    date = dt_acompanhamento,
    sex = sg_sexo,
    age = nu_idade_ano,
    weight = nu_peso,
    height = nu_altura
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

## Tidying the Data

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::mutate(
    sex =
      sex |>
      dplyr::case_match(
        "F" ~ "female",
        "M" ~ "male"
      ) |>
      factor(
        levels = c("male", "female"),
        ordered = FALSE
      )
  ) |>
  dplyr::relocate(id, date)
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

## Transforming the Data

### Adding State and Region Data

::: {.callout-note}
The [`orbis`](https://danielvartan.github.io/orbis/) R package retrieves state and region information using the [`geobr`](https://ipeagit.github.io/geobr) package, developed by the Brazilian Institute for Applied Economic Research ([IPEA](https://www.ipea.gov.br/)). The `geobr` package, in turn, is based on official data from the Brazilian Institute of Geography and Statistics ([IBGE](https://www.ibge.gov.br/)).
:::

```{r}
#| code-fold: false

brazil_municipalities <- orbis::get_brazil_municipality(
  year = plotr:::get_closest_geobr_year(year, type = "municipality")
)
```

```{r}
#| eval: false
#| include: false

brazil_municipalities |> dplyr::glimpse()
```

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::left_join(
    brazil_municipalities |>
      dplyr::mutate(
        municipality_code =
          municipality_code |>
          stringr::str_sub(end = -2) |>
          as.integer()
      ),
    by = "municipality_code"
  ) |>
  dplyr::relocate(
    id,
    date,
    region_code,
    region,
    state_code,
    state,
    federal_unit,
    municipality_code,
    municipality
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

## Validating the Data

### Removing Duplicates

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::arrange(dplyr::desc(date)) |>
  dplyr::distinct(
    id,
    age,
    date,
    weight,
    height,
    .keep_all = TRUE
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

```{r}
#| eval: false
#| include: false
#| code-fold: false

# data <-
#   data |>
#   dplyr::mutate(
#     waz = waz()
#   )
```

## Arranging the Data

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::arrange(
    region_code,
    state_code,
    municipality_code,
    date,
    sex,
    age,
    weight,
    height
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

## Data Dictionary

```{r}
metadata <-
  data |>
  labelled::`var_label<-`(
    list(
      id = "Unique identifier of the individual",
      date = "Date of the individual's nutritional assessment",
      region_code = "IBGE region code",
      region = "Region name",
      state_code = "IBGE state code",
      state = "State name",
      federal_unit = "Federal unit name",
      municipality_code = "IBGE municipality code",
      municipality = "Municipality name",
      sex = "Sex of the individual",
      age = "Age of the individual in years",
      weight = "Weight of the individual in kilograms",
      height = "Height of the individual in centimeters"
    )
  ) |>
  labelled::generate_dictionary(details = "full") |>
  labelled::convert_list_columns_to_character()
```

```{r}
metadata
```

```{r}
data
```

## Saving the Valid Data

### Data

```{r}
valid_file_pattern <- paste0(
  "valid-",
  year,
  "-age-",
  age_limits[1],
  "-",
  age_limits[2]
)
```

```{r}
data |>
  readr::write_csv(
    here::here("data", paste0(valid_file_pattern, ".csv"))
  )
```

```{r}
data |>
  readr::write_rds(
    here::here("data", paste0(valid_file_pattern, ".rds"))
  )
```

### Metadata

```{r}
metadata_file_pattern <- paste0(
  "metadata-",
  year,
  "-age-",
  age_limits[1],
  "-",
  age_limits[2]
)
```

```{r}
metadata |>
  readr::write_csv(
    here::here("data", paste0(metadata_file_pattern, ".csv"))
  )
```

```{r}
metadata |>
  readr::write_rds(
    here::here("data", paste0(metadata_file_pattern, ".rds"))
  )
```

<!-- ## Uploading the Data to OSF (Optional) -->

<!-- Only repository administrators can upload data to OSF. -->
<!-- To enable uploads, set your `OSF_PAT` environment variable with a valid OSF personal access token. -->

```{r}
#| eval: false
#| include: false

Sys.getenv("OSF_PAT") |> osfr::osf_auth()
```

```{r}
#| eval: false
#| include: false

valid_file_pattern <- paste0("beta-", valid_file_pattern)
metadata_file_pattern <- paste0("beta-", metadata_file_pattern)

osf_id <- paste0("https://osf.io/", "q7m9d")

osfr::osf_upload(
  x = osfr::osf_retrieve_node(osf_id),
  path = c(
    here::here("data", paste0(valid_file_pattern, ".csv")),
    here::here("data", paste0(valid_file_pattern, ".rds")),
    here::here("data", paste0(metadata_file_pattern, ".csv")),
    here::here("data", paste0(metadata_file_pattern, ".rds"))
  ),
  conflicts = "overwrite"
)
```

## Checking the Relative Coverage

```{r}
#| eval: false
#| include: false

valid_file_pattern <- paste0(
  "valid-",
  year,
  "-age-",
  age_limits[1],
  "-",
  age_limits[2]
)

data <- readr::read_rds(
  here::here("data", paste0(valid_file_pattern, ".rds"))
)
```

### Transforming the Data

#### Removing Duplicates by Year

::: {.callout-note}
As described in @silva2023a[p. 4], to calculate SISVAN's total resident population coverage, only the most recent record for each individual within each year is retained for analysis.
:::

```{r}
#| code-fold: false

data <-
  data |>
    dplyr::mutate(year = lubridate::year(date)) |>
    dplyr::arrange(dplyr::desc(date)) |>
    dplyr::distinct(id, year, .keep_all = TRUE) |>
    dplyr::relocate(year, .after = date)
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

#### Summarizing the Data by Year

```{r}
#| code-fold: false

data <-
  data |>
    dplyr::summarize(
      coverage = dplyr::n(),
      mean_age = age |> mean(na.rm = TRUE),
      mean_weight = weight |> mean(na.rm = TRUE),
      mean_height = height |> mean(na.rm = TRUE),
      .by = c(
        "year",
        "region_code",
        "state_code",
        "municipality_code"
      )
    )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

#### Adding Population Estimates

::: {.callout-note}
As described in the Methods section, the population estimates were obtained from the [DATASUS](https://datasus.saude.gov.br/) platform, which provides annual data by municipality, age, and sex for Brazil from 2000 to 2024 [@datasusb].

To ensure reproducibility and organization, the DATASUS data used in this pipeline are processed and validated through a separate reproducible pipeline, available [here](https://sustentarea.github.io/datasus-pop-estimates/) [@vartanian2025b]. The validated datasets are downloaded directly from [OSF](https://osf.io/). For further details, refer to the linked pipeline.
:::

```{r}
#| code-fold: false

datasus_file_pattern <- paste0("datasus-pop-estimates-", year)
```

```{r}
#| code-fold: false

datasus_file <- here::here("data", paste0(datasus_file_pattern, ".rds"))

if (!checkmate::test_file_exists(datasus_file)) {
  osf_id <-
    paste0("https://osf.io/", "h3pyd") |>
    osfr::osf_retrieve_node() |>
    osfr::osf_ls_files(
      type = "file",
      pattern = paste0("valid-", year, ".rds")
    )

  osfr::osf_download(
    x = osf_id,
    path = tempdir(),
    conflicts = "overwrite"
  ) |>
    dplyr::pull(local_path) |>
    fs::file_move(datasus_file)
}

pop_estimates <- datasus_file |> readr::read_rds()
```

```{r}
#| eval: false
#| include: false

pop_estimates |> dplyr::glimpse()
```

```{r}
#| code-fold: false

data <-
  pop_estimates |>
  dplyr::filter(dplyr::between(age, age_limits[1], age_limits[2])) |>
  dplyr::summarize(
    n = n |> sum(na.rm = TRUE),
    .by = c(
      "year",
      "region_code",
      "state_code",
      "municipality_code"
    )
  ) |>
  dplyr::mutate(
    municipality_code =
      municipality_code |>
      stringr::str_sub(end = -2) |>
      as.integer()
  ) |>
  dplyr::right_join(
    data,
    by = c(
      "year",
      "region_code",
      "state_code",
      "municipality_code"
    )
  ) |>
  dplyr::rename(population = n) |>
  dplyr::relocate(population, .before = coverage)
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

### Validating the Data

::: {.callout-note}
The population value used here is an estimate. If the SISVAN coverage for a municipality exceeds the estimated population, the population value is adjusted to match the coverage.

Note: At this stage, only the most recent record for each individual is retained.
:::

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::mutate(
    population = dplyr::case_when(
      coverage > population ~ coverage,
      TRUE ~ population
    )
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

### Calculating Relative Coverage

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::mutate(coverage_per = (coverage / population) * 100) |>
  dplyr::relocate(coverage_per, .after = coverage)
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

### Arranging the Data

```{r}
#| code-fold: false

data <-
  data |>
  dplyr::arrange(
    year,
    region_code,
    state_code,
    municipality_code
  )
```

```{r}
#| code-fold: false

data |> dplyr::glimpse()
```

### Checking Relative Coverage by Region

::: {.callout-note}
The coverage observed here is slightly lower than that reported in @silva2023a[Table 2]. This difference may be explained by the use of different data sources (Fundação Oswaldo Cruz (Fiocruz) vs. OpenDataSUS).
:::

```{r}
#| output: asis

data |>
  dplyr::mutate(region = orbis::get_brazil_region(region_code)) |>
  dplyr::summarize(
    population = population |> sum(na.rm = TRUE),
    coverage = coverage |> sum(na.rm = TRUE),
    .by = "region"
  ) |>
  dplyr::slice(c(1, 2, 5, 3, 4)) |>
  dplyr::mutate(coverage_per = (coverage / population) * 100) |>
  dplyr::rename(
    Region = region,
    Population = population,
    `SISVAN coverage` = coverage,
    `SISVAN coverage (%)` = coverage_per
  ) |>
  pal::pipe_table() |>
  pal::cat_lines()
```

### Checking Relative Coverage by State

```{r}
#| output: asis

data |>
  dplyr::mutate(state = orbis::get_brazil_state(state_code)) |>
  dplyr::summarize(
    population = population |> sum(na.rm = TRUE),
    coverage = coverage |> sum(na.rm = TRUE),
    .by = "state"
  ) |>
  dplyr::arrange(state) |>
  dplyr::mutate(coverage_per = (coverage / population) * 100) |>
  dplyr::rename(
    State = state,
    Population = population,
    `SISVAN coverage` = coverage,
    `SISVAN coverage (%)` = coverage_per
  ) |>
  pal::pipe_table() |>
  pal::cat_lines()
```

## Visualizing the Relative Coverage

```{r}
brand_div_palette <- function(x) {
  brandr:::make_color_ramp(
    n_prop = x,
    colors = c(
      brandr::get_brand_color("dark-red"),
      # brandr::get_brand_color("white"),
      brandr::get_brand_color_mix(
        position = 950,
        color_1 = "dark-red",
        color_2 = "dark-red-triadic-blue",
        alpha = 0.5
      ),
      brandr::get_brand_color("dark-red-triadic-blue")
    )
  )
}
```

```{r}
data |>
  tidyr::drop_na(coverage_per) |>
  plotr:::plot_hist(
    col = "coverage_per",
    density_line_color = brandr::get_brand_color("red"),
    x_label = "Coverage (%)",
    print = FALSE
  ) +
  ggplot2::labs(
    title = "SISVAN Coverage by Municipality (%)",
    subtitle = paste0("Year: ", year),
    caption = "Source: SISVAN"
  )
```

```{r}
#| fig-height: 6
#| fig-width: 8

data |>
  tidyr::drop_na(coverage_per, municipality_code) |>
  plotr:::plot_brazil_municipality(
    col_fill = "coverage_per",
    col_code = "municipality_code",
    year = plotr:::get_closest_geobr_year(year, type = "municipality"),
    comparable_areas = FALSE,
    breaks = seq(0, 100, 25),
    limits = c(0, 100),
    palette = brand_div_palette,
    print = FALSE
  ) +
  ggplot2::labs(
    title = "SISVAN Coverage by Municipality (%)",
    subtitle = paste0("Year: ", year),
    caption = "Source: SISVAN"
  )
```

```{r}
#| eval: false
#| include: false

grDevices::dev.off()
```

## How to Cite

To cite this work, please use the following format:

Vartanian, D., Schettino, J. P. J., & Carvalho, A. M. (2025). *A reproducible pipeline for processing SISVAN microdata on nutritional status monitoring in Brazil (2008-2023)* \[Report\]. Sustentarea Research and Extension Group at the University of São Paulo. <https://sustentarea.github.io/sisvan-nutritional-status>

A BibTeX entry for LaTeX users is

```
@techreport{vartanian2025,
  title = {A reproducible pipeline for processing SISVAN microdata on nutritional status monitoring in Brazil (2008-2023)},
  author = {{Daniel Vartanian} and {João Pedro Junqueira Schettino} and {Aline Martins de Carvalho}},
  year = {2025},
  address = {São Paulo},
  institution = {Sustentarea Research and Extension Group at the University of São Paulo},
  langid = {en},
  url = {https://sustentarea.github.io/sisvan-nutritional-status}
}
```

## License

::: {style="text-align: left;"}
[![License: MIT](https://img.shields.io/badge/License-MIT-10D810.svg)](https://choosealicense.com/licenses/mit/)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
:::

The code in this report is licensed under the [MIT License](https://opensource.org/license/mit/), while the documents are available under the [Creative Commons Attribution 4.0 International
License](https://creativecommons.org/licenses/by/4.0/).

## Acknowledgments

![](images/sustentarea-icon.svg){style="width: 15%;"}

This work is part of the [Sustentarea](https://www.fsp.usp.br/sustentarea) Research and Extension Group project: *Global syndemic: The impact of anthropogenic climate change on the health and nutrition of children under five years old attended by Brazil's public health system (SUS)*.

![](images/cnpq-logo.svg){style="width: 25%;"}

This work was supported by the Conselho Nacional de Desenvolvimento Científico e Tecnológico - Brazil ([CNPq](https://www.gov.br/cnpq/)).

## References {.unnumbered}

::: {#refs}
:::
